{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T20:34:09.641190300Z",
     "start_time": "2024-04-23T20:34:09.638190500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_DIR = '../data'\n",
    "\n",
    "# Experiment Config\n",
    "DF_NAME = 'MathQA'\n",
    "DIFFICULTY = 'easy'\n",
    "NUM_OF_SAMPLES = 500\n",
    "NUM_OF_COT = 40\n",
    "storage_dir = os.path.join(DATA_DIR, f'Evaluation_CoTs/gpt-3.5-turbo-0125')\n",
    "file_path = os.path.join(storage_dir, f'{DF_NAME}_{DIFFICULTY}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a1dc12bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:36:20.833889600Z",
     "start_time": "2024-04-23T20:36:20.810767500Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_final_answers_gsm8k(column):\n",
    "    cleaned_answers = []\n",
    "    for entry in column:\n",
    "        # Extract numbers using regular expression\n",
    "        numbers = re.findall(r'\\b\\d+\\b', str(entry))\n",
    "        if numbers:\n",
    "            # Join all numbers with space if there are multiple numbers\n",
    "            cleaned_answers.append(' '.join(numbers))\n",
    "        else:\n",
    "            # If no number is found, replace with 'error'\n",
    "            cleaned_answers.append('error')\n",
    "    return cleaned_answers\n",
    "def clean_final_answers_MC(column):\n",
    "    cleaned_answers = []\n",
    "    for entry in column:\n",
    "        # Extract numbers using regular expression\n",
    "        entry = str(entry).lower()\n",
    "        options = re.findall(r'[abcde]\\s?\\)', str(entry))\n",
    "        if options:\n",
    "            # Join all numbers with space if there are multiple numbers\n",
    "            cleaned_answers.append(options[0][0])\n",
    "        else:\n",
    "            # If no number is found, replace with 'error'\n",
    "            cleaned_answers.append(entry)\n",
    "    return cleaned_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c9fe6d5066ce4fd7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T20:36:21.670881600Z",
     "start_time": "2024-04-23T20:36:21.559962900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Rosie can run 10 miles per hour for 3 hours. After that, she runs 5 miles per hour. How many miles can she run in 7 hours? ,'"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.startswith('Final Answer_'):\n",
    "        df[col] = clean_final_answers_MC(df[col])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "828defcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T20:36:41.310294900Z",
     "start_time": "2024-04-23T20:36:41.027145700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "result_dict = {\n",
    "    'id':[],\n",
    "    'correct answer': [],\n",
    "    'CoT answers':[],\n",
    "    'length':[],\n",
    "    'instruction violation':[],\n",
    "    'internal mistake':[]\n",
    "}\n",
    "tmp = []\n",
    "for col in df.columns:\n",
    "    if col.startswith('Final Answer_'):\n",
    "        tmp.append(df[col].to_numpy())\n",
    "tmp_arr = np.vstack(tmp)\n",
    "cot_answer_li = tmp_arr.T\n",
    "# Count Steps\n",
    "step_count_buffer = []\n",
    "for col in df:\n",
    "    if col.startswith('CoT_'):\n",
    "        cleaned_answers = []\n",
    "        for entry in df[col]:\n",
    "            # Extract numbers using regular expression\n",
    "            steps = re.findall(r'[Ss]tep\\s?\\d', str(entry))\n",
    "            if steps:\n",
    "                # Join all numbers with space if there are multiple numbers\n",
    "                cleaned_answers.append(len(steps))\n",
    "            else:\n",
    "                # If no number is found, replace with 'error'\n",
    "                cleaned_answers.append(0)\n",
    "        step_count_buffer.append(cleaned_answers)\n",
    "\n",
    "step_count = np.array(step_count_buffer).T\n",
    "# Violate instruction\n",
    "instruction_buffer = []\n",
    "for col in df:\n",
    "    if col.startswith('Instruction Violation_'):\n",
    "        cleaned_answers = []\n",
    "        for entry in df[col]:\n",
    "            # Extract numbers using regular expression\n",
    "            x = ast.literal_eval(entry)\n",
    "            cleaned_answers.append(sum([sum(idx) for idx in x]))\n",
    "        instruction_buffer.append(cleaned_answers)\n",
    "\n",
    "instruction_error = np.array(instruction_buffer).T\n",
    "\n",
    "# Internal Mistake mentioned\n",
    "mistake_buffer = []\n",
    "for col in df:\n",
    "    if col.startswith('CoT_'):\n",
    "        cleaned_answers = []\n",
    "        for entry in df[col]:\n",
    "            # Extract numbers using regular expression\n",
    "            misktake = re.findall(r'(be a mistake)|(be an error)', str(entry))\n",
    "            if misktake:\n",
    "                cleaned_answers.append(1)\n",
    "            else:\n",
    "                # If no number is found, replace with 'error'\n",
    "                cleaned_answers.append(0)\n",
    "        mistake_buffer.append(cleaned_answers)\n",
    "\n",
    "mistakes = np.array(mistake_buffer).T\n",
    "assert cot_answer_li.shape == step_count.shape == instruction_error.shape == mistakes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a9ed7735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T19:46:58.873219500Z",
     "start_time": "2024-04-23T19:46:58.857557100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        -9867630.0\n1         3431580.0\n2       322886700.0\n3        -6887448.0\n4        21459061.0\n           ...     \n495           100.0\n496      23252172.0\n497            50.0\n498    -425561.9444\n499     2901807.833\nName: Correct Answer, Length: 500, dtype: object"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for row in range(len(df)):\n",
    "    cot_li_sample = cot_answer_li[row]\n",
    "    length_li_sample = step_count[row]\n",
    "    IV_li_sample = instruction_error[row]\n",
    "    mistake_sample = mistakes[row]\n",
    "    result_dict['id'].append(row)\n",
    "    result_dict['correct answer'].append(df.iloc[row]['Correct Answer'])\n",
    "    result_dict['CoT answers'].append(cot_li_sample)\n",
    "    result_dict['length'].append(length_li_sample)\n",
    "    result_dict['instruction violation'].append(IV_li_sample)\n",
    "    result_dict['internal mistake'].append(mistake_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3551d911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T19:09:22.599911600Z",
     "start_time": "2024-04-23T19:09:22.544720600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.DataFrame.from_dict(result_dict)\n",
    "df_final['Question'] = df['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "707e9fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a multiple choice test consists of 4 questions , and each question has 5 answer choices . in how many r ways can the test be completed if every question is unanswered ? The options are: a ) 24 , b ) 120 , c ) 625 , d ) 720 , e ) 1024'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Question'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cdb47d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(row):\n",
    "    correctness_list = []\n",
    "    correct_answer = row['correct answer']\n",
    "    cot_answers = row['CoT answers']\n",
    "    question = row['Question']\n",
    "    for i in range(len(cot_answers)):\n",
    "        correct = correct_answer\n",
    "        cot = cot_answers[i]\n",
    "        q = question\n",
    "        cot = str(cot)\n",
    "        if(cot == correct):\n",
    "            correctness_list.append(1)\n",
    "            continue\n",
    "        # Extract the options and their corresponding values from the question\n",
    "        options = {}\n",
    "        for option in ['a', 'b', 'c', 'd', 'e']:\n",
    "            if option + ' )' in q:\n",
    "                value = q.split(option + ' )')[-1].strip().split(',')[0].strip()\n",
    "                options[option] = value\n",
    "        if options[correct] in cot:\n",
    "            correctness_list.append(1)\n",
    "        else:\n",
    "            correctness_list.append(0)\n",
    "    \n",
    "    return correctness_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e92e3a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2      [1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, ...\n",
       "3      [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...\n",
       "4      [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, ...\n",
       "                             ...                        \n",
       "495    [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, ...\n",
       "496    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "497    [1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, ...\n",
       "498    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "499    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...\n",
       "Name: correctness, Length: 500, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['correctness'] = df_final.apply(check_correctness, axis=1)\n",
    "df_final['correctness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75ded779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                       1\n",
       "correct answer                                                           b\n",
       "CoT answers              [e, e, c, a, e, 5 / 9, c, d, c, c, e, 5 / 9, c...\n",
       "length                   [4, 3, 3, 4, 3, 4, 3, 3, 3, 6, 3, 3, 3, 3, 3, ...\n",
       "instruction violation    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "internal mistake         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Question                 a 3 - digit positive integer is chosen at rand...\n",
       "correctness              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e684aba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n",
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def concatenate_columns(df,data_columns, outcome_column):\n",
    "    # Initialize an empty dictionary to store the concatenated data\n",
    "    concatenated_data = {}\n",
    "    \n",
    "    # Get the number of rows based on the length of the outcome column\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Iterate over each column\n",
    "    for column in data_columns+[outcome_column]:\n",
    "        # Initialize an empty list to store the concatenated values for the current column\n",
    "        concatenated_values = []\n",
    "        \n",
    "        # Iterate over each row\n",
    "        for i in range(num_rows):\n",
    "            # Get the list of values for the current column and row\n",
    "            values = df[column][i]\n",
    "            \n",
    "            # Concatenate the values into a single string\n",
    "            concatenated_values += list(values)\n",
    "            \n",
    "        \n",
    "        # Add the concatenated values to the dictionary with the column name as the key\n",
    "        concatenated_data[column] = concatenated_values\n",
    "        print(len(concatenated_values))\n",
    "    # Add the outcome column to the concatenated data dictionary\n",
    "    \n",
    "    # Create a DataFrame from the concatenated data dictionary\n",
    "    df_final = pd.DataFrame(concatenated_data)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "df_final = concatenate_columns(df_final,['length','instruction violation','internal mistake'],'correctness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "89314ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = DATA_DIR+'/Data_For_Analysis/' + f'{DF_NAME}_{DIFFICULTY}_CS.csv'\n",
    "df_final.to_csv(save_dir,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e7c8038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:33:09.023629200Z",
     "start_time": "2024-04-23T17:33:08.993181400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 'Braveheart', 'B': 'Popeye', 'C': 'House II The Second Story', 'D': 'In China They Eat Dogs'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Find a movie similar to Dances with Wolves, The Shawshank Redemption, Apollo 13, Schindler's List:\\r\\nOptions:\\r\\n(A) Braveheart\\r\\n(B) Popeye\\r\\n(C) House II The Second Story\\r\\n(D) In China They Eat Dogs\\r\""
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "llm_hall_project",
   "language": "python",
   "display_name": "llm_hall"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
