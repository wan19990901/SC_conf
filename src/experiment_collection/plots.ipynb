{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:04:35.509447600Z",
     "start_time": "2024-05-30T23:04:35.497190600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab5f1b69fe1325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:04:38.395412Z",
     "start_time": "2024-05-30T23:04:35.513454700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IDV_CS_Model import *\n",
    "from CS_based_early_stopping import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sys\n",
    "import json\n",
    "DATA_DIR = '../data/Evaluation_CoTs/Algo_Design_Data/'\n",
    "# DF_NAME = 'GSM8K'\n",
    "# DIFFICULTY = 'easy'\n",
    "# NUM_OF_SAMPLES = 500\n",
    "# NUM_OF_COT = 40\n",
    "# MODEL = 'gpt-3.5-turbo-0125'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3725e5db76cfbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:04:38.673422500Z",
     "start_time": "2024-05-30T23:04:38.397432600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(DATA_DIR, 'final_extracted.json')\n",
    "df_with_features_raw = pd.read_json(file_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0fd5e936aafd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:04:40.885228600Z",
     "start_time": "2024-05-30T23:04:38.682684900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_li =['LEN','QUA_IM','DIF_IV','SIM_INPUT','SIM_COT_BIGRAM','SIM_COT_AGG','SIM_AC_BIGRAM','SIM_AC_PW']\n",
    "df_with_features_raw = df_with_features_raw[~df_with_features_raw.Model.str.startswith('gpt-4')]\n",
    "\n",
    "_,df_with_features = train_test_split_stratify(df_with_features_raw,test_size=0.3,random_state =2024)\n",
    "_, coef = trained_LR_model(df_with_features_raw, feature_li, report_auroc=False,train_mode=True)\n",
    "print(coef)\n",
    "coe = coef[1:]\n",
    "intercept = coef[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d600673f344d53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:04:40.931322500Z",
     "start_time": "2024-05-30T23:04:40.889800100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_with_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3626774f0f478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:28:13.548975200Z",
     "start_time": "2024-05-30T23:28:13.513542600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'benchmark': ['all','GSM8K_hard','GSM8K_test','MathQA_challenge_test','MathQA_dev','BigBench_hard','BigBench_easy'],\n",
    "    'llm' : ['all','gpt-3.5','claude-3','llama3'],\n",
    "    'N': [i for i in range(2,16)],\n",
    "    'threshold': [0.1*i for i in range(11)],\n",
    "    'stop_algo':['PositiveN','ConsistencyN'],\n",
    "    'approximator': [customized_LR_model,trained_LR_model]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12bdea0f2aca36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:28:14.415221400Z",
     "start_time": "2024-05-30T23:28:14.400968800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(df,benchmark='all',llm = 'all'):\n",
    "    if benchmark == 'all':\n",
    "        df_ = df\n",
    "    else:\n",
    "        df_ = df[df.Name == benchmark]\n",
    "    \n",
    "    if llm == 'gpt-4':\n",
    "        df_final = df_[df_.Model.str.startswith('gpt-4')]\n",
    "    elif llm == 'gpt-3.5':\n",
    "        df_final = df_[df_.Model.str.startswith('gpt-3')]\n",
    "    elif llm == 'claude-3':\n",
    "        df_final = df_[df_.Model.str.startswith('claude-3')]\n",
    "    elif llm == 'llama3':\n",
    "        df_final = df_[df_.Model.str.startswith('llama3')]\n",
    "    else:\n",
    "        df_final = df_\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676b7a9030b3ba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:30:17.967970300Z",
     "start_time": "2024-05-30T23:30:17.935136900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for benchmark in config['benchmark']:\n",
    "    print(len(get_data(df_with_features,benchmark=benchmark)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db36abe2db78100d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# step vs acc main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc25d46e4ab361e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T01:27:27.876904400Z",
     "start_time": "2024-05-31T01:27:21.008628Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_buffer = {\n",
    "        'llm': [],\n",
    "        'benchmark':[],\n",
    "        'N': [],\n",
    "        'stop_algo':[],\n",
    "        'threshold': [],\n",
    "        'SC_ACC': [],\n",
    "        'ES_ACC': [],\n",
    "        'ASC_ACC': [],\n",
    "        'CASC_ACC': [],\n",
    "        'SC_Avg_Cost': [],\n",
    "        'ES_Avg_Cost': [],\n",
    "        'ASC_Avg_Cost': [],\n",
    "        'CASC_Avg_Cost': [],\n",
    "    }\n",
    "for benchmark in config['benchmark']:\n",
    "    for llm in config['llm']:\n",
    "        df_in = get_data(df_with_features,benchmark=benchmark,llm=llm)\n",
    "        print(llm,benchmark)\n",
    "        print('df_size is ',len(df_in))\n",
    "        df_cs = customized_LR_model(df_in,feature_li,coe,intercept)\n",
    "        N = 3\n",
    "        threshold = 0.1\n",
    "        stop_mechanism = 'PositiveN'\n",
    "        df_results = CS_early_stopping(df=df_cs, threshold=threshold, N=N, stop_mechanism=stop_mechanism)\n",
    "        df_model_comp_dict = {\n",
    "                'llm': llm,\n",
    "                'benchmark':benchmark,\n",
    "                'N': N,\n",
    "                'stop_algo':stop_mechanism,\n",
    "                'threshold': threshold,\n",
    "                'SC_ACC': round(df_results.SC_correctness.sum() / len(df_results),4),\n",
    "                'ES_ACC': round(df_results.ES_correctness.sum() / len(df_results),4),\n",
    "                'ASC_ACC': round(df_results.asc_correctness.sum() / len(df_results),4),\n",
    "                'CASC_ACC': round(df_results.CS_correctness.sum() / len(df_results),4),\n",
    "                'SC_Avg_Cost': 40,\n",
    "                'ES_Avg_Cost': round(df_results.ES_steps.mean(),2),\n",
    "                'ASC_Avg_Cost': round(df_results.asc_steps.mean(),2),\n",
    "                'CASC_Avg_Cost': round(df_results.CS_steps.mean(),2),\n",
    "            }\n",
    "        for key,val in df_model_comp_dict.items():\n",
    "            result_buffer[key].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f97f245b8ed85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T01:27:27.918495Z",
     "start_time": "2024-05-31T01:27:27.874903600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_main_table = pd.DataFrame(result_buffer)\n",
    "# df_main_table.to_csv('main_table.csv',index=False)\n",
    "# df_main_table = pd.read_csv('../src/experiment_collection/main_table.csv')\n",
    "df_main_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6090acee45fabb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# N study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704164f313697c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:10:02.995023Z",
     "start_time": "2024-05-30T23:08:36.493762900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_buffer = {\n",
    "        'llm': [],\n",
    "        'benchmark':[],\n",
    "        'N': [],\n",
    "        'stop_algo':[],\n",
    "        'threshold': [],\n",
    "        'SC_ACC': [],\n",
    "        'ES_ACC': [],\n",
    "        'ASC_ACC': [],\n",
    "        'CASC_ACC': [],\n",
    "        'SC_Avg_Cost': [],\n",
    "        'ES_Avg_Cost': [],\n",
    "        'ASC_Avg_Cost': [],\n",
    "        'CASC_Avg_Cost': [],\n",
    "    }\n",
    "for N in config['N']:\n",
    "    for benchmark in config['benchmark']:\n",
    "        for llm in config['llm']:\n",
    "            df_in = get_data(df_with_features,benchmark=benchmark,llm=llm)\n",
    "            print(llm,benchmark)\n",
    "            print('df_size is ',len(df_in))\n",
    "            df_cs = customized_LR_model(df_in,feature_li,coe,intercept)\n",
    "            threshold = 0.1\n",
    "            stop_mechanism = 'PositiveN'\n",
    "            df_results = CS_early_stopping(df=df_cs, threshold=threshold, N=N, stop_mechanism=stop_mechanism)\n",
    "            df_model_comp_dict = {\n",
    "                    'llm': llm,\n",
    "                    'benchmark':benchmark,\n",
    "                    'N': N,\n",
    "                    'stop_algo':stop_mechanism,\n",
    "                    'threshold': threshold,\n",
    "                    'SC_ACC': round(df_results.SC_correctness.sum() / len(df_results),4),\n",
    "                    'ES_ACC': round(df_results.ES_correctness.sum() / len(df_results),4),\n",
    "                    'ASC_ACC': round(df_results.asc_correctness.sum() / len(df_results),4),\n",
    "                    'CASC_ACC': round(df_results.CS_correctness.sum() / len(df_results),4),\n",
    "                    'SC_Avg_Cost': 40,\n",
    "                    'ES_Avg_Cost': round(df_results.ES_steps.mean(),2),\n",
    "                    'ASC_Avg_Cost': round(df_results.asc_steps.mean(),2),\n",
    "                    'CASC_Avg_Cost': round(df_results.CS_steps.mean(),2),\n",
    "                }\n",
    "            for key,val in df_model_comp_dict.items():\n",
    "                result_buffer[key].append(val)\n",
    "df_N_study = pd.DataFrame(result_buffer)\n",
    "# df_N_study.to_csv('N_study_table.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f384e02e0185c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:10:03.038709100Z",
     "start_time": "2024-05-30T23:10:03.001766200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_N_study = pd.read_csv('../src/experiment_collection/N_study_table.csv')\n",
    "df_N_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c499962475278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:10:03.084199300Z",
     "start_time": "2024-05-30T23:10:03.027195Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_zeros_with_previous_nonzero(initialize, arr):\n",
    "    # Initialize a variable to keep track of the last non-zero value\n",
    "    last_nonzero = initialize\n",
    "    \n",
    "    # Iterate over the array\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] != 0:\n",
    "            # Update the last non-zero value\n",
    "            last_nonzero = arr[i]\n",
    "        else:\n",
    "            # Replace zero with the last non-zero value\n",
    "            arr[i] = last_nonzero\n",
    "            \n",
    "    return arr\n",
    "# Create the line plot with solid lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e3a8970fe56d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:10:20.682214400Z",
     "start_time": "2024-05-30T23:10:03.146982600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "llm = 'all'\n",
    "benchmark = 'all'\n",
    "print(llm,benchmark)\n",
    "sc_step_results = []\n",
    "df_step = get_data(df_with_features,benchmark=benchmark,llm = llm)\n",
    "for row_idx in range(len(df_step)):\n",
    "    sample_results = []\n",
    "    for i in range(40):\n",
    "        if Counter(df_step['CoT answers'].iloc[row_idx][:i+1]).most_common(1)[0][0] == df_step['correct answer'].iloc[row_idx]:\n",
    "            sample_results.append(1)\n",
    "        else:\n",
    "            sample_results.append(0)\n",
    "    sc_step_results.append(sample_results)\n",
    "sc_step_results = np.array(sc_step_results)\n",
    "sc_step_results = sc_step_results.sum(axis=0)/sc_step_results.shape[0]\n",
    "df_N_study_gpt4 = df_N_study[(df_N_study.llm == llm)]\n",
    "df_N_study_gpt4_all = df_N_study_gpt4[df_N_study_gpt4.benchmark == benchmark]\n",
    "casc_steps = df_N_study_gpt4_all['CASC_Avg_Cost'].to_numpy().astype(np.int32)\n",
    "casc_acc = df_N_study_gpt4_all['CASC_ACC'].to_numpy()\n",
    "casc_step_results = np.zeros(40)\n",
    "for i, idx in enumerate(casc_steps):\n",
    "    casc_step_results[idx] = casc_acc[i]\n",
    "casc_step_results = replace_zeros_with_previous_nonzero(sc_step_results[0],casc_step_results)\n",
    "\n",
    "es_steps = []\n",
    "es_acc = []\n",
    "for i in range(16):\n",
    "    df_es_step = calculate_ES_correctness(df_step,i+1)\n",
    "    es_acc.append(round(df_es_step.ES_correctness.sum() / len(df_es_step),4))\n",
    "    es_steps.append(df_es_step.ES_steps.mean().astype(np.int32))\n",
    "es_step_results = np.zeros(40)\n",
    "for i, idx in enumerate(es_steps):\n",
    "    es_step_results[idx] = es_acc[i]\n",
    "es_step_results = replace_zeros_with_previous_nonzero(sc_step_results[0],es_step_results)\n",
    "\n",
    "asc_steps = []\n",
    "asc_acc = []\n",
    "for i in range(75,101):\n",
    "    df_asc_step = calculate_ASC_correctness(df_step,i*0.01)\n",
    "    asc_acc.append(round(df_asc_step.asc_correctness.sum() / len(df_asc_step),4))\n",
    "    asc_steps.append(df_asc_step.asc_steps.mean().astype(np.int32))\n",
    "asc_step_results = np.zeros(40)\n",
    "for i, idx in enumerate(asc_steps):\n",
    "    asc_step_results[idx-1] = asc_acc[i]\n",
    "asc_step_results = replace_zeros_with_previous_nonzero(sc_step_results[0],asc_step_results)\n",
    "\n",
    "step_study_plot_dict = {\n",
    "    'Steps': np.arange(40)[1:],\n",
    "    'SC': sc_step_results[1:],\n",
    "    'ES': es_step_results[1:],\n",
    "    'ASC': asc_step_results[1:],\n",
    "    'CASC':casc_step_results[1:]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "sns.lineplot(data=step_study_plot_dict, x='Steps', y='SC', label='SC', linestyle='-')\n",
    "sns.lineplot(data=step_study_plot_dict, x='Steps', y='ES', label='ES', linestyle='-')\n",
    "sns.lineplot(data=step_study_plot_dict, x='Steps', y='ASC', label='ASC', linestyle='-')\n",
    "sns.lineplot(data=step_study_plot_dict, x='Steps', y='CASC', label='CASC', linestyle='-')\n",
    "\n",
    "# Set the x and y axis labels\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('ACC')\n",
    "\n",
    "# Find the intersection point\n",
    "x_intercept = None\n",
    "for i in range(len(step_study_plot_dict['Steps']) - 1):\n",
    "    if step_study_plot_dict['CASC'][i] < sc_step_results.max() <= step_study_plot_dict['CASC'][i+1]:\n",
    "        x_intercept = step_study_plot_dict['Steps'][i]+1\n",
    "        break\n",
    "\n",
    "# Add the horizontal line (red line)\n",
    "plt.hlines(y=0.45, xmin=x_intercept, xmax=40, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "# Add the vertical line at the intersection point\n",
    "if x_intercept is not None:\n",
    "    plt.vlines(x=x_intercept, ymin=sc_step_results.min(), ymax=0.45, color='red', linestyle='--', linewidth=1)\n",
    "    plt.annotate(f'({x_intercept}, {0.45})', xy=(x_intercept, 0.45), \n",
    "                 xytext=(x_intercept - 5.7, 0.45),\n",
    "                 fontsize=9, color='black')\n",
    "\n",
    "# Display the plot\n",
    "plt.legend()\n",
    "plt.savefig('../src/experiment_collection/main_step_acc_plot.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786728a597e449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:10:21.163145100Z",
     "start_time": "2024-05-30T23:10:20.690794200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "casc_N = df_N_study_gpt4_all['N'].to_numpy()\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the first line (ACC) with ax1\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('N')\n",
    "ax1.set_ylabel('ACC', color=color)\n",
    "line1, = ax1.plot(casc_N, casc_acc, color=color, label='ACC')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "plt.hlines(y=casc_acc[2], xmin=0, xmax=3, color='red', linestyle='--', linewidth=1)\n",
    "plt.annotate(f'({3}, {casc_acc[2]})', xy=(3, casc_acc[2]), \n",
    "                 xytext=(3 - 2, casc_acc[2]+0.001),\n",
    "                 fontsize=9, color='black')\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Avg Steps', color=color)\n",
    "line2, = ax2.plot(casc_N, casc_steps, color=color, label='Avg Steps')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "plt.vlines(x=3, ymin=0, ymax=22, color='red', linestyle='--', linewidth=1)\n",
    "plt.hlines(y=casc_steps[2], xmin=3, xmax=14, color='red', linestyle='--', linewidth=1)\n",
    "plt.annotate(f'({3}, {casc_steps[2]})', xy=(3, casc_steps[2]), \n",
    "                 xytext=(3 +0.5, casc_steps[2]-1),\n",
    "                 fontsize=9, color='black')\n",
    "# Combine legends\n",
    "lines = [line1, line2]\n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "fig.savefig('../src/experiment_collection/N_study_plot.jpg', dpi=300, bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd233b5303a7ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Threshold Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f6174c29f89e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:11:28.586168900Z",
     "start_time": "2024-05-30T23:10:21.164188300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_buffer = {\n",
    "        'llm': [],\n",
    "        'benchmark':[],\n",
    "        'N': [],\n",
    "        'stop_algo':[],\n",
    "        'threshold': [],\n",
    "        'SC_ACC': [],\n",
    "        'ES_ACC': [],\n",
    "        'ASC_ACC': [],\n",
    "        'CASC_ACC': [],\n",
    "        'SC_Avg_Cost': [],\n",
    "        'ES_Avg_Cost': [],\n",
    "        'ASC_Avg_Cost': [],\n",
    "        'CASC_Avg_Cost': [],\n",
    "    }\n",
    "for threshold in config['threshold']:\n",
    "    for benchmark in config['benchmark']:\n",
    "        for llm in config['llm']:\n",
    "            df_in = get_data(df_with_features,benchmark=benchmark,llm=llm)\n",
    "            print(llm,benchmark)\n",
    "            print('df_size is ',len(df_in))\n",
    "            df_cs = customized_LR_model(df_in,feature_li,coe,intercept)\n",
    "            N= 3\n",
    "            stop_mechanism = 'PositiveN'\n",
    "            df_results = CS_early_stopping(df=df_cs, threshold=threshold, N=N, stop_mechanism=stop_mechanism)\n",
    "            df_model_comp_dict = {\n",
    "                    'llm': llm,\n",
    "                    'benchmark':benchmark,\n",
    "                    'N': N,\n",
    "                    'stop_algo':stop_mechanism,\n",
    "                    'threshold': threshold,\n",
    "                    'SC_ACC': round(df_results.SC_correctness.sum() / len(df_results),4),\n",
    "                    'ES_ACC': round(df_results.ES_correctness.sum() / len(df_results),4),\n",
    "                    'ASC_ACC': round(df_results.asc_correctness.sum() / len(df_results),4),\n",
    "                    'CASC_ACC': round(df_results.CS_correctness.sum() / len(df_results),4),\n",
    "                    'SC_Avg_Cost': 40,\n",
    "                    'ES_Avg_Cost': round(df_results.ES_steps.mean(),2),\n",
    "                    'ASC_Avg_Cost': round(df_results.asc_steps.mean(),2),\n",
    "                    'CASC_Avg_Cost': round(df_results.CS_steps.mean(),2),\n",
    "                }\n",
    "            for key,val in df_model_comp_dict.items():\n",
    "                result_buffer[key].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c8adacdef871a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:11:28.596987500Z",
     "start_time": "2024-05-30T23:11:28.584161300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_threshold_study = pd.DataFrame(result_buffer)\n",
    "# df_threshold_study.to_csv('threshold_study_table.csv',index=False)\n",
    "# df_threshold_study = pd.read_csv('../src/experiment_collection/threshold_study_table.csv')\n",
    "# df_threshold_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2eb8537c925799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:11:29.068756400Z",
     "start_time": "2024-05-30T23:11:28.613215400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_threshold_study_gpt4 = df_threshold_study[(df_threshold_study.llm == llm)]\n",
    "df_threshold_study_gpt4_all = df_threshold_study_gpt4[df_threshold_study_gpt4.benchmark == benchmark]\n",
    "th_casc_steps = df_threshold_study_gpt4_all['CASC_Avg_Cost'].to_numpy()\n",
    "th_casc_acc = df_threshold_study_gpt4_all['CASC_ACC'].to_numpy()\n",
    "th_casc_threshold = df_threshold_study_gpt4_all['threshold'].to_numpy()\n",
    "# Create a figure and axis\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the first line (ACC) with ax1\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Threshold')\n",
    "ax1.set_ylabel('ACC', color=color)\n",
    "line1, = ax1.plot(th_casc_threshold, th_casc_acc, color=color, label='ACC')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "plt.hlines(y=th_casc_acc[5], xmin=0, xmax=0.5, color='red', linestyle='--', linewidth=1)\n",
    "plt.annotate(f'({0.5}, {th_casc_acc[5]})', xy=(0.5, th_casc_acc[5]), \n",
    "                 xytext=(0.5 + 0.02, th_casc_acc[5]-0.01),\n",
    "                 fontsize=9, color='black')\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Avg Steps', color=color)\n",
    "line2, = ax2.plot(th_casc_threshold, th_casc_steps, color=color, label='Avg Steps')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "plt.vlines(x=0.5, ymin=0, ymax=40, color='red', linestyle='--', linewidth=1)\n",
    "plt.hlines(y=th_casc_steps[1], xmin=0.1, xmax=1, color='red', linestyle='--', linewidth=1)\n",
    "plt.annotate(f'({0.5}, {6})', xy=(0.5, th_casc_steps[5]), \n",
    "                 xytext=(0.5 - 0.1, th_casc_steps[5]+1),\n",
    "                 fontsize=9, color='black')\n",
    "# Combine legends\n",
    "lines = [line1, line2]\n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "plt.savefig(\"Threshold.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3c1ab4de438ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T23:11:29.357326Z",
     "start_time": "2024-05-30T23:11:29.066707700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lineplot( x=th_casc_steps, y=th_casc_acc, label='ACC', linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342dc1983431368c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "th_casc_acc[5]\n",
    "th_casc_steps[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e02be0d3638fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Stop algo study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b0d8b5bd0071b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# result_buffer = {\n",
    "#         'llm': [],\n",
    "#         'benchmark':[],\n",
    "#         'N': [],\n",
    "#         'stop_algo':[],\n",
    "#         'threshold': [],\n",
    "#         'SC_ACC': [],\n",
    "#         'ES_ACC': [],\n",
    "#         'ASC_ACC': [],\n",
    "#         'CASC_ACC': [],\n",
    "#         'SC_Avg_Cost': [],\n",
    "#         'ES_Avg_Cost': [],\n",
    "#         'ASC_Avg_Cost': [],\n",
    "#         'CASC_Avg_Cost': [],\n",
    "#     }\n",
    "# for stop_mechanism in config['stop_algo']:\n",
    "#     for benchmark in config['benchmark']:\n",
    "#         for llm in config['llm']:\n",
    "#             df_in = get_data(df_with_features,benchmark=benchmark,llm=llm)\n",
    "#             print(llm,benchmark)\n",
    "#             print('df_size is ',len(df_in))\n",
    "#             df_cs, _ = config['approximator'][0](df=df_in, feature_li=feature_li, coe=coe, intercept=intercept)\n",
    "#             N= 3\n",
    "#             threshold = 0.5\n",
    "#             df_results, _ = CS_early_stopping(df=df_cs, threshold=threshold, N=N, stop_mechanism=stop_mechanism)\n",
    "#             df_model_comp_dict = {\n",
    "#                     'llm': llm,\n",
    "#                     'benchmark':benchmark,\n",
    "#                     'N': N,\n",
    "#                     'stop_algo':stop_mechanism,\n",
    "#                     'threshold': threshold,\n",
    "#                     'SC_ACC': round(df_results.SC_correctness.sum() / len(df_results),4),\n",
    "#                     'ES_ACC': round(df_results.ES_correctness.sum() / len(df_results),4),\n",
    "#                     'ASC_ACC': round(df_results.asc_correctness.sum() / len(df_results),4),\n",
    "#                     'CASC_ACC': round(df_results.CS_correctness.sum() / len(df_results),4),\n",
    "#                     'SC_Avg_Cost': 40,\n",
    "#                     'ES_Avg_Cost': round(df_results.ES_steps.mean(),2),\n",
    "#                     'ASC_Avg_Cost': round(df_results.asc_steps.mean(),2),\n",
    "#                     'CASC_Avg_Cost': round(df_results.CS_steps.mean(),2),\n",
    "#                 }\n",
    "#             for key,val in df_model_comp_dict.items():\n",
    "#                 result_buffer[key].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087c5c3ce393ae7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_stop_algo_study = pd.DataFrame(result_buffer)\n",
    "# df_stop_algo_study.to_csv('stop_algo_study_table.csv',index=False)\n",
    "df_N_study_2 = pd.read_csv('../src/experiment_collection/N_study_table_ConsistencyN.csv')\n",
    "df_N_study = pd.read_csv('../src/experiment_collection/N_study_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d9e13b5b291a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "llm = 'all'\n",
    "benchmark = 'all'\n",
    "print(llm,benchmark)\n",
    "sc_step_results = []\n",
    "df_step = get_data(df_with_features,benchmark=benchmark,llm = llm)\n",
    "for row_idx in range(len(df_step)):\n",
    "    sample_results = []\n",
    "    for i in range(40):\n",
    "        if Counter(df_step['CoT answers'].iloc[row_idx][:i+1]).most_common(1)[0][0] == df_step['correct answer'].iloc[row_idx]:\n",
    "            sample_results.append(1)\n",
    "        else:\n",
    "            sample_results.append(0)\n",
    "    sc_step_results.append(sample_results)\n",
    "sc_step_results = np.array(sc_step_results)\n",
    "sc_step_results = sc_step_results.sum(axis=0)/sc_step_results.shape[0]\n",
    "\n",
    "df_N_study_gpt4 = df_N_study[(df_N_study.llm == llm)]\n",
    "df_N_study_gpt4_all = df_N_study_gpt4[df_N_study_gpt4.benchmark == benchmark]\n",
    "casc_steps = df_N_study_gpt4_all['CASC_Avg_Cost'].to_numpy().astype(np.int32)\n",
    "casc_acc = df_N_study_gpt4_all['CASC_ACC'].to_numpy()\n",
    "casc_step_results = np.zeros(40)\n",
    "for i, idx in enumerate(casc_steps):\n",
    "    casc_step_results[idx] = casc_acc[i]\n",
    "casc_step_results = replace_zeros_with_previous_nonzero(sc_step_results[0],casc_step_results)\n",
    "\n",
    "df_N_study_gpt4_2 = df_N_study_2[(df_N_study_2.llm == llm)]\n",
    "df_N_study_gpt4_2_all = df_N_study_gpt4_2[df_N_study_gpt4_2.benchmark == benchmark]\n",
    "casc_steps_2 = df_N_study_gpt4_2_all['CASC_Avg_Cost'].to_numpy().astype(np.int32)\n",
    "casc_acc_2 = df_N_study_gpt4_2_all['CASC_ACC'].to_numpy()\n",
    "casc_step_results_2 = np.zeros(40)\n",
    "for i, idx in enumerate(casc_steps_2):\n",
    "    casc_step_results_2[idx] = casc_acc_2[i]\n",
    "casc_step_results_2 = replace_zeros_with_previous_nonzero(sc_step_results[0],casc_step_results_2)\n",
    "\n",
    "es_steps = []\n",
    "es_acc = []\n",
    "for i in range(16):\n",
    "    df_es_step = calculate_ES_correctness(df_step,i+1)\n",
    "    es_acc.append(round(df_es_step.ES_correctness.sum() / len(df_es_step),4))\n",
    "    es_steps.append(df_es_step.ES_steps.mean().astype(np.int32))\n",
    "es_step_results = np.zeros(40)\n",
    "for i, idx in enumerate(es_steps):\n",
    "    es_step_results[idx] = es_acc[i]\n",
    "es_step_results = replace_zeros_with_previous_nonzero(sc_step_results[0],es_step_results)\n",
    "\n",
    "asc_steps = []\n",
    "asc_acc = []\n",
    "for i in range(75,101):\n",
    "    df_asc_step = calculate_ASC_correctness(df_step,i*0.01)\n",
    "    asc_acc.append(round(df_asc_step.asc_correctness.sum() / len(df_asc_step),4))\n",
    "    asc_steps.append(df_asc_step.asc_steps.mean().astype(np.int32))\n",
    "asc_step_results = np.zeros(40)\n",
    "for i, idx in enumerate(asc_steps):\n",
    "    asc_step_results[idx-1] = asc_acc[i]\n",
    "asc_step_results = replace_zeros_with_previous_nonzero(sc_step_results[0],asc_step_results)\n",
    "\n",
    "step_study_plot_dict = {\n",
    "    'Steps': np.arange(40)[1:],\n",
    "    'SC': sc_step_results[1:],\n",
    "    'ES': es_step_results[1:],\n",
    "    'ASC': asc_step_results[1:],\n",
    "    'CASC_PositiveN':casc_step_results[1:],\n",
    "    'CASC_ConsistencyN':casc_step_results_2[1:]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "# sns.lineplot(data=step_study_plot_dict, x='Steps', y='SC', label='SC', linestyle='-')\n",
    "# sns.lineplot(data=step_study_plot_dict, x='Steps', y='ES', label='ES', linestyle='-')\n",
    "# sns.lineplot(data=step_study_plot_dict, x='Steps', y='ASC', label='ASC', linestyle='-')\n",
    "sns.lineplot(data=step_study_plot_dict, x='Steps', y='CASC_PositiveN', label='CASC_PositiveN', linestyle='-')\n",
    "sns.lineplot(data=step_study_plot_dict, x='Steps', y='CASC_ConsistencyN', label='CASC_ConsistencyN', linestyle='-')\n",
    "\n",
    "# Set the x and y axis labels\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('ACC')\n",
    "\n",
    "# Find the intersection point\n",
    "x_intercept = None\n",
    "for i in range(len(step_study_plot_dict['Steps']) - 1):\n",
    "    if step_study_plot_dict['CASC_PositiveN'][i] < sc_step_results.max() <= step_study_plot_dict['CASC_PositiveN'][i+1]:\n",
    "        x_intercept = step_study_plot_dict['Steps'][i]+1\n",
    "        break\n",
    "\n",
    "# Add the horizontal line (red line)\n",
    "plt.hlines(y=0.545, xmin=x_intercept, xmax=40, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "# Add the vertical line at the intersection point\n",
    "if x_intercept is not None:\n",
    "    plt.vlines(x=x_intercept, ymin=sc_step_results.min(), ymax=0.545, color='red', linestyle='--', linewidth=1)\n",
    "    plt.annotate(f'({x_intercept}, {0.545})', xy=(x_intercept, 0.545), \n",
    "                 xytext=(x_intercept - 5.7, 0.545),\n",
    "                 fontsize=9, color='black')\n",
    "\n",
    "# Display the plot\n",
    "plt.legend()\n",
    "plt.savefig('../src/experiment_collection/stop_algo_study_plot.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e223a8795ab5e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
